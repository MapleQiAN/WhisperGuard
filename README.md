# 🛡️ WhisprGuard：语义隐私助手（中国语境下的文本风险检测工具）

> **说话的艺术，不是说得多，而是说得稳。**  
> WhisprGuard 是一个面向中文写作者、自媒体用户、公众号编辑者的语义风险检测 AI Agent，专注于识别你文章中的 **“不能说、最好别说、再说就没了”** 的表达。

---

## 🔍 背景与痛点

在中国互联网语境下，文本审核早已超越了敏感词匹配——它更像是一种**语义政治学**，一个由模糊表达、情绪暗示和上下文隐喻组成的博弈过程。

**你没说错，但你说得不对。**

WhisprGuard 就是为了解决这个问题而生：在**你点击“发布”之前**，告诉你哪句话可能让你吃“红码”、被限流，甚至删号。

---

## 💡 项目特点

- 🧠 **敏感语义识别**：检测隐含敏感话题，如历史事件、政治批评、宗教民族争议等
- 📕 **本地敏感词匹配**：关键词、模糊词、emoji/拼音变体检测
- 🤖 **AI 风险评分引擎**：调用语言模型判断整体表达的风险等级
- ✏️ **改写建议生成**：提供委婉/讽刺/平稳表达替代版本
- 🎯 **适配中国平台语境**：特别优化微信公众号、微博、知乎等平台语义逻辑

---

## 🧱 项目结构

```
whisprguard/
├── go_service/       # 主服务，检测敏感词，调用语义服务
├── py_service/       # 语义风险分析与改写建议（Python服务）
├── shared/           # 公共词库、测试用例
├── deploy/           # 部署配置，如 Docker
├── README.md
└── LICENSE
```

---

## 🚀 快速启动

```bash
# 启动 Python 服务
cd py_service
pip install -r requirements.txt
uvicorn app:app --reload

# 启动 Go 服务
cd ../go_service
go run main.go
```

---

## 📦 示例调用

```json
POST /analyze
{
  "text": "听说他们最近删帖越来越狠了。"
}
```

返回：
```json
{
  "sensitive_words": ["删帖"],
  "risk_level": "高",
  "risk_reason": "表达对公共舆论控制的不满，具有政治批评倾向",
  "rewrite": [
    "最近一些平台内容处理机制更频繁了。",
    "有些话题现在不太适合公开讨论。"
  ]
}
```

---

## 🧾 使用建议

- 发公众号文章前检测一遍，避免违规删稿
- 写评论、发微博时规避高危表达
- 用作新闻/论文文本预审参考
- 想说又不能说时，让 AI 帮你“润色”

---

## 🔒 免责声明

本项目仅供学习研究使用，不构成对内容合法性的担保。请用户自行判断合规风险。

---

WhisprGuard —— 你说话前的最后一位朋友。
